{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you have to add twitter Developer account api keys\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_token_secret = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = 53.43084848150311   # geographical centre of search\n",
    "longitude = -2.9608694861754525    # geographical centre of search\n",
    "max_range = 300      # search range in kilometres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authenticate with credentials\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = ['Park -filter:retweets']\n",
    "limit = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextClean(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r'@[a-z0-9_]\\S+', '', tweet)\n",
    "    tweet = re.sub(r'#[a-z0-9_]\\S+', '', tweet)\n",
    "    tweet = re.sub(r'&[a-z0-9_]\\S+', '', tweet)\n",
    "    tweet = re.sub(r'[?!.+,;$%&\"]+', '', tweet)\n",
    "    tweet = re.sub(r'rt[\\s]+', '', tweet)\n",
    "    tweet = re.sub(r'\\d+', '', tweet)\n",
    "    tweet = re.sub(r'\\$', '', tweet)\n",
    "    tweet = re.sub(r'rt+', '', tweet)\n",
    "    tweet = re.sub(r'https?:?\\/\\/\\S+', '', tweet)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_search(key_word):\n",
    "    i = 0\n",
    "    tweets_df = pd.DataFrame(columns=['Datetime', 'Tweet', 'Username', 'Retweets', 'Followers'])\n",
    "    for tweet in tweepy.Cursor(api.search_tweets, q = key_word,geocode = \"%f,%f,%dkm\" % (latitude, longitude, max_range) ,count = 100, lang = 'en', tweet_mode = 'extended').items():\n",
    "        print('Tweets downloaded:', i, '/', limit, end = '\\r')\n",
    "        if tweet.user.followers_count > 200:\n",
    "            tweets_df = tweets_df.append({'Datetime': tweet.created_at,\n",
    "                                          'Tweet': tweet.full_text,\n",
    "                                          'Username': tweet.user.screen_name,\n",
    "                                          'Retweets': tweet.retweet_count,\n",
    "                                          'Followers': tweet.user.followers_count}, ignore_index = True)\n",
    "            i += 1\n",
    "        if i >= limit:\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    tweets_df['Datetime'] = pd.to_datetime(tweets_df['Datetime'], format = '%Y.%m.%d %H:%M:%S')\n",
    "    tweets_df.drop_duplicates(subset = ['Tweet'], inplace = True)\n",
    "    tweets_df['CleanTweet'] = tweets_df['Tweet'].apply(TextClean)\n",
    "    tweets_df['CleanTweet2'] = tweets_df['Tweet'].apply(TextClean)\n",
    "    tweets_df['CleanTweet2'] = tweets_df['CleanTweet2'].apply(remove_emojis)\n",
    "    tweet_tokenizer = TweetTokenizer()\n",
    "    tweets_df['CleanTweet'] = tweets_df['CleanTweet'].apply(tweet_tokenizer.tokenize)\n",
    "    tweets_df['CleanTweet'] = [', '.join(map(str, token)) for token in tweets_df['CleanTweet']]\n",
    "    \n",
    "    return tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets downloaded: 9999 / 10000187 / 10000 473 / 10000 554 / 10000 708 / 10000 1086 / 10000 1181 / 10000 1271 / 10000 1363 / 10000 1469 / 10000 1536 / 10000 1617 / 10000 1693 / 10000 1844 / 10000 1931 / 10000 2092 / 10000 2272 / 10000 2475 / 10000 2564 / 10000 2634 / 10000 2702 / 10000 2775 / 10000 2912 / 10000 3004 / 10000 3084 / 10000 3157 / 10000 3235 / 10000 3447 / 10000 3527 / 10000 3602 / 10000 3672 / 10000 3914 / 10000 3992 / 10000 4073 / 10000 4351 / 10000 4797 / 10000 4858 / 10000 4941 / 100001000010000 6226 / 100006976 / 10000 7286 / 10000 7659 / 100007834 / 10000 10000 8084 / 10000 9164 / 10000\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Username</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Followers</th>\n",
       "      <th>CleanTweet</th>\n",
       "      <th>CleanTweet2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-23 23:52:11+00:00</td>\n",
       "      <td>@elfrootloops I blame South Park for that one ðŸ˜‚</td>\n",
       "      <td>vee4vampy</td>\n",
       "      <td>0</td>\n",
       "      <td>839</td>\n",
       "      <td>i, blame, south, park, for, that, one, ðŸ˜‚</td>\n",
       "      <td>i blame south park for that one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-23 23:50:20+00:00</td>\n",
       "      <td>@ClimateWarrior7 Avoid Regents Park Zoo. I hea...</td>\n",
       "      <td>oldboyinuk</td>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "      <td>avoid, regents, park, zoo, i, hear, it's, a, p...</td>\n",
       "      <td>avoid regents park zoo i hear it's a pox-spot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-23 23:47:37+00:00</td>\n",
       "      <td>next season i think we need to focus on breaki...</td>\n",
       "      <td>Kikirani19</td>\n",
       "      <td>0</td>\n",
       "      <td>376</td>\n",
       "      <td>next, season, i, think, we, need, to, focus, o...</td>\n",
       "      <td>next season i think we need to focus on breaki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-23 23:42:15+00:00</td>\n",
       "      <td>Gowran park \\n\\n16.50. 12.4.14\\n17.20. 6.16\\n1...</td>\n",
       "      <td>hollins48</td>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>gowran, park, :</td>\n",
       "      <td>gowran park \\n\\n \\n \\n \\n \\n \\n :\\n \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-23 23:41:46+00:00</td>\n",
       "      <td>@OffasTyke You arenâ€™t alone!  I watched two pe...</td>\n",
       "      <td>fascinatorfun</td>\n",
       "      <td>0</td>\n",
       "      <td>80198</td>\n",
       "      <td>you, aren, â€™, t, alone, i, watched, two, peopl...</td>\n",
       "      <td>you arenâ€™t alone  i watched two people one af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>2022-05-19 16:52:11+00:00</td>\n",
       "      <td>Matlock to Darley Dale riverside walk \\nDistan...</td>\n",
       "      <td>Coco_Travels</td>\n",
       "      <td>1</td>\n",
       "      <td>2998</td>\n",
       "      <td>matlock, to, darley, dale, riverside, walk, di...</td>\n",
       "      <td>matlock to darley dale riverside walk \\ndistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>2022-05-19 16:52:10+00:00</td>\n",
       "      <td>Our website is updated. Now weâ€™re concentratin...</td>\n",
       "      <td>HALOApparelUK2</td>\n",
       "      <td>0</td>\n",
       "      <td>516</td>\n",
       "      <td>our, website, is, updated, now, we, â€™, re, con...</td>\n",
       "      <td>our website is updated now weâ€™re concentrating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>2022-05-19 16:52:00+00:00</td>\n",
       "      <td>Campaigners have already raised Â£130,000\\nhttp...</td>\n",
       "      <td>BristolLive</td>\n",
       "      <td>0</td>\n",
       "      <td>154009</td>\n",
       "      <td>campaigners, have, already, raised, Â£</td>\n",
       "      <td>campaigners have already raised Â£\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>2022-05-19 16:51:54+00:00</td>\n",
       "      <td>This afternoon I attended at Park Hill School ...</td>\n",
       "      <td>AkefAkbar</td>\n",
       "      <td>0</td>\n",
       "      <td>3112</td>\n",
       "      <td>this, afternoon, i, attended, at, park, hill, ...</td>\n",
       "      <td>this afternoon i attended at park hill school ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>2022-05-19 16:51:33+00:00</td>\n",
       "      <td>Alleged rape Q&amp;amp;A: What we know so far abou...</td>\n",
       "      <td>BNTeesside</td>\n",
       "      <td>0</td>\n",
       "      <td>13221</td>\n",
       "      <td>alleged, rape, q, what, we, know, so, far, abo...</td>\n",
       "      <td>alleged rape q what we know so far about polic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9976 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Datetime  \\\n",
       "0    2022-05-23 23:52:11+00:00   \n",
       "1    2022-05-23 23:50:20+00:00   \n",
       "2    2022-05-23 23:47:37+00:00   \n",
       "3    2022-05-23 23:42:15+00:00   \n",
       "4    2022-05-23 23:41:46+00:00   \n",
       "...                        ...   \n",
       "9971 2022-05-19 16:52:11+00:00   \n",
       "9972 2022-05-19 16:52:10+00:00   \n",
       "9973 2022-05-19 16:52:00+00:00   \n",
       "9974 2022-05-19 16:51:54+00:00   \n",
       "9975 2022-05-19 16:51:33+00:00   \n",
       "\n",
       "                                                  Tweet        Username  \\\n",
       "0       @elfrootloops I blame South Park for that one ðŸ˜‚       vee4vampy   \n",
       "1     @ClimateWarrior7 Avoid Regents Park Zoo. I hea...      oldboyinuk   \n",
       "2     next season i think we need to focus on breaki...      Kikirani19   \n",
       "3     Gowran park \\n\\n16.50. 12.4.14\\n17.20. 6.16\\n1...       hollins48   \n",
       "4     @OffasTyke You arenâ€™t alone!  I watched two pe...   fascinatorfun   \n",
       "...                                                 ...             ...   \n",
       "9971  Matlock to Darley Dale riverside walk \\nDistan...    Coco_Travels   \n",
       "9972  Our website is updated. Now weâ€™re concentratin...  HALOApparelUK2   \n",
       "9973  Campaigners have already raised Â£130,000\\nhttp...     BristolLive   \n",
       "9974  This afternoon I attended at Park Hill School ...       AkefAkbar   \n",
       "9975  Alleged rape Q&amp;A: What we know so far abou...      BNTeesside   \n",
       "\n",
       "     Retweets Followers                                         CleanTweet  \\\n",
       "0           0       839           i, blame, south, park, for, that, one, ðŸ˜‚   \n",
       "1           0       344  avoid, regents, park, zoo, i, hear, it's, a, p...   \n",
       "2           0       376  next, season, i, think, we, need, to, focus, o...   \n",
       "3           0       736                                    gowran, park, :   \n",
       "4           0     80198  you, aren, â€™, t, alone, i, watched, two, peopl...   \n",
       "...       ...       ...                                                ...   \n",
       "9971        1      2998  matlock, to, darley, dale, riverside, walk, di...   \n",
       "9972        0       516  our, website, is, updated, now, we, â€™, re, con...   \n",
       "9973        0    154009              campaigners, have, already, raised, Â£   \n",
       "9974        0      3112  this, afternoon, i, attended, at, park, hill, ...   \n",
       "9975        0     13221  alleged, rape, q, what, we, know, so, far, abo...   \n",
       "\n",
       "                                            CleanTweet2  \n",
       "0                      i blame south park for that one   \n",
       "1      avoid regents park zoo i hear it's a pox-spot...  \n",
       "2     next season i think we need to focus on breaki...  \n",
       "3              gowran park \\n\\n \\n \\n \\n \\n \\n :\\n \\n    \n",
       "4      you arenâ€™t alone  i watched two people one af...  \n",
       "...                                                 ...  \n",
       "9971  matlock to darley dale riverside walk \\ndistan...  \n",
       "9972  our website is updated now weâ€™re concentrating...  \n",
       "9973                campaigners have already raised Â£\\n  \n",
       "9974  this afternoon i attended at park hill school ...  \n",
       "9975  alleged rape q what we know so far about polic...  \n",
       "\n",
       "[9976 rows x 7 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.DataFrame()\n",
    "for x in key_words:\n",
    "    df =tweet_search(x)\n",
    "    tweets_df=tweets_df.append(df, ignore_index=True)\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame\n",
    "tweets_df.to_csv('Park liverpool 2_3.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
