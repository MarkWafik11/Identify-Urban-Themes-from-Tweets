{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dc909562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in d:\\software\\anaconda\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: pandas-profiling==2.* in d:\\software\\anaconda\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: htmlmin>=0.1.12 in d:\\software\\anaconda\\lib\\site-packages (from pandas-profiling==2.*) (0.1.12)\n",
      "Requirement already satisfied: confuse>=1.0.0 in d:\\software\\anaconda\\lib\\site-packages (from pandas-profiling==2.*) (1.7.0)\n",
      "Requirement already satisfied: phik>=0.11.1 in d:\\software\\anaconda\\lib\\site-packages (from pandas-profiling==2.*) (0.12.2)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in d:\\software\\anaconda\\lib\\site-packages (from pandas-profiling==2.*) (4.62.3)\n",
      "Requirement already satisfied: tangled-up-in-unicode>=0.0.6 in d:\\software\\anaconda\\lib\\site-packages (from pandas-profiling==2.*) (0.2.0)\n",
      "Requirement already satisfied: requests>=2.24.0 in d:\\software\\anaconda\\lib\\site-packages (from pandas-profiling==2.*) (2.27.1)\n",
      "Requirement already satisfied: matplotlib>=3.2.0 in d:\\software\\anaconda\\lib\\site-packages (from pandas-profiling==2.*) (3.4.3)\n",
      "Requirement already satisfied: joblib in d:\\software\\anaconda\\lib\\site-packages (from pandas-profiling==2.*) (1.1.0)\n",
      "Requirement already satisfied: visions[type_image_path]==0.7.1 in d:\\software\\anaconda\\lib\\site-packages (from pandas-profiling==2.*) (0.7.1)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in d:\\software\\anaconda\\lib\\site-packages (from pandas-profiling==2.*) (1.3.4)\n",
      "Requirement already satisfied: attrs>=19.3.0 in d:\\software\\anaconda\\lib\\site-packages (from pandas-profiling==2.*) (21.2.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in d:\\software\\anaconda\\lib\\site-packages (from pandas-profiling==2.*) (1.7.1)\n",
      "Requirement already satisfied: missingno>=0.4.2 in d:\\software\\anaconda\\lib\\site-packages (from pandas-profiling==2.*) (0.5.1)\n",
      "Requirement already satisfied: seaborn>=0.10.1 in d:\\software\\anaconda\\lib\\site-packages (from pandas-profiling==2.*) (0.11.2)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in d:\\software\\anaconda\\lib\\site-packages (from pandas-profiling==2.*) (2.11.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in d:\\software\\anaconda\\lib\\site-packages (from pandas-profiling==2.*) (1.20.3)\n",
      "Requirement already satisfied: multimethod==1.4 in d:\\software\\anaconda\\lib\\site-packages (from visions[type_image_path]==0.7.1->pandas-profiling==2.*) (1.4)\n",
      "Requirement already satisfied: networkx>=2.4 in d:\\software\\anaconda\\lib\\site-packages (from visions[type_image_path]==0.7.1->pandas-profiling==2.*) (2.6.3)\n",
      "Requirement already satisfied: bottleneck in d:\\software\\anaconda\\lib\\site-packages (from visions[type_image_path]==0.7.1->pandas-profiling==2.*) (1.3.2)\n",
      "Requirement already satisfied: imagehash in d:\\software\\anaconda\\lib\\site-packages (from visions[type_image_path]==0.7.1->pandas-profiling==2.*) (4.2.1)\n",
      "Requirement already satisfied: Pillow in d:\\software\\anaconda\\lib\\site-packages (from visions[type_image_path]==0.7.1->pandas-profiling==2.*) (8.4.0)\n",
      "Requirement already satisfied: pyyaml in d:\\software\\anaconda\\lib\\site-packages (from confuse>=1.0.0->pandas-profiling==2.*) (6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\software\\anaconda\\lib\\site-packages (from jinja2>=2.11.1->pandas-profiling==2.*) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling==2.*) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling==2.*) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling==2.*) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling==2.*) (3.0.4)\n",
      "Requirement already satisfied: six in d:\\software\\anaconda\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.2.0->pandas-profiling==2.*) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\software\\anaconda\\lib\\site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas-profiling==2.*) (2021.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\software\\anaconda\\lib\\site-packages (from requests>=2.24.0->pandas-profiling==2.*) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\software\\anaconda\\lib\\site-packages (from requests>=2.24.0->pandas-profiling==2.*) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\software\\anaconda\\lib\\site-packages (from requests>=2.24.0->pandas-profiling==2.*) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\software\\anaconda\\lib\\site-packages (from requests>=2.24.0->pandas-profiling==2.*) (2.0.4)\n",
      "Requirement already satisfied: colorama in d:\\software\\anaconda\\lib\\site-packages (from tqdm>=4.48.2->pandas-profiling==2.*) (0.3.9)\n",
      "Requirement already satisfied: PyWavelets in d:\\software\\anaconda\\lib\\site-packages (from imagehash->visions[type_image_path]==0.7.1->pandas-profiling==2.*) (1.1.1)\n",
      "Requirement already satisfied: plotly==4.* in d:\\software\\anaconda\\lib\\site-packages (4.14.3)\n",
      "Requirement already satisfied: six in d:\\software\\anaconda\\lib\\site-packages (from plotly==4.*) (1.16.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in d:\\software\\anaconda\\lib\\site-packages (from plotly==4.*) (1.3.3)\n",
      "Collecting en-core-web-lg==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.2.0/en_core_web_lg-3.2.0-py3-none-any.whl (777.4 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in d:\\software\\anaconda\\lib\\site-packages (from en-core-web-lg==3.2.0) (3.2.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: click<8.1.0 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.20.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.27.1)\n",
      "Requirement already satisfied: setuptools in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (58.0.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (21.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in d:\\software\\anaconda\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: colorama in d:\\software\\anaconda\\lib\\site-packages (from click<8.1.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.3.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\software\\anaconda\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in d:\\software\\anaconda\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\software\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\software\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\software\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\software\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\software\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\software\\anaconda\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n",
      "Requirement already satisfied: pyldavis in d:\\software\\anaconda\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: future in d:\\software\\anaconda\\lib\\site-packages (from pyldavis) (0.18.2)\n",
      "Requirement already satisfied: numexpr in d:\\software\\anaconda\\lib\\site-packages (from pyldavis) (2.7.3)\n",
      "Requirement already satisfied: gensim in d:\\software\\anaconda\\lib\\site-packages (from pyldavis) (4.1.2)\n",
      "Requirement already satisfied: setuptools in d:\\software\\anaconda\\lib\\site-packages (from pyldavis) (58.0.4)\n",
      "Requirement already satisfied: scipy in d:\\software\\anaconda\\lib\\site-packages (from pyldavis) (1.7.1)\n",
      "Requirement already satisfied: joblib in d:\\software\\anaconda\\lib\\site-packages (from pyldavis) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in d:\\software\\anaconda\\lib\\site-packages (from pyldavis) (1.20.3)\n",
      "Requirement already satisfied: jinja2 in d:\\software\\anaconda\\lib\\site-packages (from pyldavis) (2.11.3)\n",
      "Requirement already satisfied: funcy in d:\\software\\anaconda\\lib\\site-packages (from pyldavis) (1.17)\n",
      "Requirement already satisfied: pandas>=1.2.0 in d:\\software\\anaconda\\lib\\site-packages (from pyldavis) (1.3.4)\n",
      "Requirement already satisfied: scikit-learn in d:\\software\\anaconda\\lib\\site-packages (from pyldavis) (0.24.2)\n",
      "Requirement already satisfied: sklearn in d:\\software\\anaconda\\lib\\site-packages (from pyldavis) (0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\software\\anaconda\\lib\\site-packages (from pandas>=1.2.0->pyldavis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\software\\anaconda\\lib\\site-packages (from pandas>=1.2.0->pyldavis) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\software\\anaconda\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyldavis) (1.16.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in d:\\software\\anaconda\\lib\\site-packages (from gensim->pyldavis) (5.2.1)\n",
      "Requirement already satisfied: Cython==0.29.23 in d:\\software\\anaconda\\lib\\site-packages (from gensim->pyldavis) (0.29.23)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\software\\anaconda\\lib\\site-packages (from jinja2->pyldavis) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\software\\anaconda\\lib\\site-packages (from scikit-learn->pyldavis) (2.2.0)\n",
      "Requirement already satisfied: gensim in d:\\software\\anaconda\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in d:\\software\\anaconda\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: Cython==0.29.23 in d:\\software\\anaconda\\lib\\site-packages (from gensim) (0.29.23)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in d:\\software\\anaconda\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in d:\\software\\anaconda\\lib\\site-packages (from gensim) (1.20.3)\n",
      "Requirement already satisfied: chart_studio in d:\\software\\anaconda\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: six in d:\\software\\anaconda\\lib\\site-packages (from chart_studio) (1.16.0)\n",
      "Requirement already satisfied: requests in d:\\software\\anaconda\\lib\\site-packages (from chart_studio) (2.27.1)\n",
      "Requirement already satisfied: retrying>=1.3.3 in d:\\software\\anaconda\\lib\\site-packages (from chart_studio) (1.3.3)\n",
      "Requirement already satisfied: plotly in d:\\software\\anaconda\\lib\\site-packages (from chart_studio) (4.14.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\software\\anaconda\\lib\\site-packages (from requests->chart_studio) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\software\\anaconda\\lib\\site-packages (from requests->chart_studio) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\software\\anaconda\\lib\\site-packages (from requests->chart_studio) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\software\\anaconda\\lib\\site-packages (from requests->chart_studio) (3.2)\n",
      "Requirement already satisfied: autopep8 in d:\\software\\anaconda\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: pycodestyle>=2.8.0 in d:\\software\\anaconda\\lib\\site-packages (from autopep8) (2.8.0)\n",
      "Requirement already satisfied: toml in d:\\software\\anaconda\\lib\\site-packages (from autopep8) (0.10.2)\n"
     ]
    }
   ],
   "source": [
    "    !pip install emoji --upgrade\n",
    "    !pip install pandas-profiling==2.*\n",
    "    !pip install plotly==4.*\n",
    "    !python -m spacy download en_core_web_lg\n",
    "    !pip install pyldavis\n",
    "    !pip install gensim\n",
    "    !pip install chart_studio\n",
    "    !pip install --upgrade autopep8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a12a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "\n",
    "#Base and Cleaning \n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "import regex\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "#Visualizations\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import chart_studio\n",
    "import chart_studio.plotly as py \n",
    "import chart_studio.tools as tls\n",
    "\n",
    "#Natural Language Processing (NLP)\n",
    "import spacy\n",
    "import gensim\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel, LdaState\n",
    "from gensim.parsing.preprocessing import STOPWORDS as SW\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "from wordcloud import STOPWORDS\n",
    "stopwords = set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "712ebd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_emoji_free_text(text):\n",
    "    \"\"\"\n",
    "    Removes emoji's from tweets\n",
    "    Accepts:\n",
    "        Text (tweets)\n",
    "    Returns:\n",
    "        Text (emoji free tweets)\n",
    "    \"\"\"\n",
    "    emoji_list = [c for c in text if c in emoji.UNICODE_EMOJI]\n",
    "    clean_text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "    return clean_text\n",
    "\n",
    "def url_free_text(text):\n",
    "    '''\n",
    "    Cleans text from urls\n",
    "    '''\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the function above and get tweets free of emoji's\n",
    "call_emoji_free = lambda x: give_emoji_free_text(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48e62536",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Random Tweets 13000 3_4.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cc3aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply `call_emoji_free` which calls the function to remove all emoji's\n",
    "df['emoji_free_tweets'] = df['Tweet'].apply(call_emoji_free)\n",
    "\n",
    "#Create a new column with url free tweets\n",
    "df['url_free_tweets'] = df['emoji_free_tweets'].apply(url_free_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f2ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dbc1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "\n",
    "# Custom stopwords\n",
    "custom_stopwords = ['hi','\\n','\\n\\n', '&amp;', ' ', '.', '-', 'got', \"it's\", 'it’s', \"i'm\", 'i’m', 'im', 'want', 'like', \n",
    "                    '$', '@']\n",
    "\n",
    "# Customize stop words by adding to the default list\n",
    "STOP_WORDS = nlp.Defaults.stop_words.union(custom_stopwords)\n",
    "\n",
    "# ALL_STOP_WORDS = spacy + gensim + wordcloud\n",
    "ALL_STOP_WORDS = STOP_WORDS.union(SW).union(stopwords)\n",
    "\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(df['url_free_tweets'], batch_size=500):\n",
    "    doc_tokens = []    \n",
    "    for token in doc: \n",
    "        if token.text.lower() not in STOP_WORDS:\n",
    "            doc_tokens.append(token.text.lower())   \n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "# Makes tokens column\n",
    "df['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7665781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_back_to_text'] = [' '.join(map(str, l)) for l in df['tokens']]\n",
    "\n",
    "def get_lemmas(text):\n",
    "    '''Used to lemmatize the processed tweets'''\n",
    "    lemmas = []\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Something goes here :P\n",
    "    for token in doc: \n",
    "        if ((token.is_stop == False) and (token.is_punct == False)) and (token.pos_ != 'PRON'):\n",
    "            lemmas.append(token.lemma_)\n",
    "    \n",
    "    return lemmas\n",
    "\n",
    "df['lemmas'] = df['tokens_back_to_text'].apply(get_lemmas)\n",
    "# Make lemmas a string again\n",
    "df['lemmas_back_to_text'] = [' '.join(map(str, l)) for l in df['lemmas']]\n",
    "\n",
    "# Tokenizer function\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Parses a string into a list of semantic units (words)\n",
    "    Args:\n",
    "        text (str): The string that the function will tokenize.\n",
    "    Returns:\n",
    "        list: tokens parsed out\n",
    "    \"\"\"\n",
    "    # Removing url's\n",
    "    pattern = r\"http\\S+\"\n",
    "    \n",
    "    tokens = re.sub(pattern, \"\", text) # https://www.youtube.com/watch?v=O2onA4r5UaY\n",
    "    tokens = re.sub('[^a-zA-Z 0-9]', '', text)\n",
    "    tokens = re.sub('[%s]' % re.escape(string.punctuation), '', text) # Remove punctuation\n",
    "    tokens = re.sub('\\\\w*\\\\d\\\\w*', '', text) # Remove words containing numbers\n",
    "    tokens = re.sub('@*!*\\\\$*', '', text) # Remove @ ! $\n",
    "    tokens = tokens.strip(',') # TESTING THIS LINE\n",
    "    tokens = tokens.strip('?') # TESTING THIS LINE\n",
    "    tokens = tokens.strip('!') # TESTING THIS LINE\n",
    "    tokens = tokens.strip(\"'\") # TESTING THIS LINE\n",
    "    tokens = tokens.strip(\".\") # TESTING THIS LINE\n",
    "\n",
    "    tokens = tokens.lower().split() # Make text lowercase and split it\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Apply tokenizer\n",
    "df['lemma_tokens'] = df['lemmas_back_to_text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d16cbee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32927\n"
     ]
    }
   ],
   "source": [
    "# Create a id2word dictionary\n",
    "id2word = Dictionary(df['lemma_tokens'])\n",
    "print(len(id2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f491e939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10872\n"
     ]
    }
   ],
   "source": [
    "# Filtering Extremes\n",
    "id2word.filter_extremes(no_below=2, no_above=.99)\n",
    "print(len(id2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3000156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a corpus object \n",
    "corpus = [id2word.doc2bow(d) for d in df['lemma_tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "247ae99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Topic 0 ------\n",
      "good people today new book april love way x 😭\n",
      "\n",
      "------ Topic 1 ------\n",
      "🤣 year good £ time 😂 ⬛ day people think\n",
      "\n",
      "------ Topic 2 ------\n",
      "😂 ️ look ⬜ thank good ❤ yes feel time\n",
      "\n",
      "------ Topic 3 ------\n",
      "think people thank need work time look new team go\n",
      "\n",
      "------ Topic 4 ------\n",
      "️ know week day right time new people come think\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiating a Base LDA model \n",
    "base_model = LdaMulticore(corpus=corpus, num_topics=5, id2word=id2word, workers=12, passes=5)\n",
    "# Filtering for words \n",
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in base_model.print_topics()]\n",
    "# Create Topics\n",
    "topics = [' '.join(t[0:10]) for t in words]\n",
    "# Getting the topics\n",
    "for id, t in enumerate(topics): \n",
    "    print(f\"------ Topic {id} ------\")\n",
    "    print(t, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5652fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "# a measure of how good the model is. lower the better\n",
    "base_perplexity = base_model.log_perplexity(corpus)\n",
    "print('\\nPerplexity: ', base_perplexity) \n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model = CoherenceModel(model=base_model, texts=df['lemma_tokens'], \n",
    "                                   dictionary=id2word, coherence='c_v')\n",
    "coherence_lda_model_base = coherence_model.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda_model_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7f33c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Username</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Followers</th>\n",
       "      <th>CleanTweet</th>\n",
       "      <th>CleanTweet2</th>\n",
       "      <th>Vader_sent</th>\n",
       "      <th>TextBlob_sent</th>\n",
       "      <th>Different_sent</th>\n",
       "      <th>Topic</th>\n",
       "      <th>emoji_free_tweets</th>\n",
       "      <th>url_free_tweets</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_back_to_text</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>lemmas_back_to_text</th>\n",
       "      <th>lemma_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@FPL_Banger @Move78_FPL Yeah have for some tim...</td>\n",
       "      <td>fplbooster</td>\n",
       "      <td>0</td>\n",
       "      <td>3314</td>\n",
       "      <td>yeah, have, for, some, time, now, yet, keep, s...</td>\n",
       "      <td>yeah have for some time now yet keep scouting 😂</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>@FPL_Banger @Move78_FPL Yeah have for some tim...</td>\n",
       "      <td>@FPL_Banger @Move78_FPL Yeah have for some tim...</td>\n",
       "      <td>[@fpl_banger, @move78_fpl, yeah, time, now,, s...</td>\n",
       "      <td>@fpl_banger @move78_fpl yeah time now, scouting 😂</td>\n",
       "      <td>[@fpl_banger, @move78_fpl, yeah, time, scout, 😂]</td>\n",
       "      <td>@fpl_banger @move78_fpl yeah time scout 😂</td>\n",
       "      <td>[fpl_banger, move78_fpl, yeah, time, scout, 😂]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>@Simonhartmp - we haven’t moved on and just be...</td>\n",
       "      <td>bernardshawlive</td>\n",
       "      <td>0</td>\n",
       "      <td>2287</td>\n",
       "      <td>-, we, haven, ’, t, moved, on, and, just, beca...</td>\n",
       "      <td>- we haven’t moved on and just because you sa...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>@Simonhartmp - we haven’t moved on and just be...</td>\n",
       "      <td>@Simonhartmp - we haven’t moved on and just be...</td>\n",
       "      <td>[@simonhartmp, haven’t, moved, it,, doesn’t, s...</td>\n",
       "      <td>@simonhartmp haven’t moved it, doesn’t so. nee...</td>\n",
       "      <td>[@simonhartmp, move, need, clear, lot, corrupt...</td>\n",
       "      <td>@simonhartmp move need clear lot corrupt liar ...</td>\n",
       "      <td>[simonhartmp, move, need, clear, lot, corrupt,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>@may_achie It's not our country anymore 😔</td>\n",
       "      <td>ChattyMan9</td>\n",
       "      <td>0</td>\n",
       "      <td>1269</td>\n",
       "      <td>it's, not, our, country, anymore, 😔</td>\n",
       "      <td>it's not our country anymore 😔</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>@may_achie It's not our country anymore 😔</td>\n",
       "      <td>@may_achie It's not our country anymore 😔</td>\n",
       "      <td>[@may_achie, country, anymore, 😔]</td>\n",
       "      <td>@may_achie country anymore 😔</td>\n",
       "      <td>[@may_achie, country, anymore, 😔]</td>\n",
       "      <td>@may_achie country anymore 😔</td>\n",
       "      <td>[may_achie, country, anymore, 😔]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>COL'S CRIMINAL LIBRARY: 2 BY MARK SAFRANKO htt...</td>\n",
       "      <td>col2910</td>\n",
       "      <td>0</td>\n",
       "      <td>2234</td>\n",
       "      <td>col's, criminal, library, :, by, mark, safranko</td>\n",
       "      <td>col's criminal library:  by mark safranko</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>COL'S CRIMINAL LIBRARY: 2 BY MARK SAFRANKO htt...</td>\n",
       "      <td>COL'S CRIMINAL LIBRARY: 2 BY MARK SAFRANKO</td>\n",
       "      <td>[col's, criminal, library:, 2, mark, safranko]</td>\n",
       "      <td>col's criminal library: 2 mark safranko</td>\n",
       "      <td>[col, criminal, library, 2, mark, safranko]</td>\n",
       "      <td>col criminal library 2 mark safranko</td>\n",
       "      <td>[col, criminal, library, 2, mark, safranko]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6 months free, next goal is a year https://t.c...</td>\n",
       "      <td>TomLea__</td>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>months, free, next, goal, is, a, year</td>\n",
       "      <td>months free next goal is a year</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6 months free, next goal is a year https://t.c...</td>\n",
       "      <td>6 months free, next goal is a year</td>\n",
       "      <td>[6, months, free,, goal, year]</td>\n",
       "      <td>6 months free, goal year</td>\n",
       "      <td>[6, month, free, goal, year]</td>\n",
       "      <td>6 month free goal year</td>\n",
       "      <td>[6, month, free, goal, year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12985</th>\n",
       "      <td>12985</td>\n",
       "      <td>12985</td>\n",
       "      <td>@coopefnbr @Jeffiwnl @nowaylildavid @Matiqeee ...</td>\n",
       "      <td>TeekewFNBR</td>\n",
       "      <td>0</td>\n",
       "      <td>1351</td>\n",
       "      <td>init, bit, odd</td>\n",
       "      <td>init bit odd</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>@coopefnbr @Jeffiwnl @nowaylildavid @Matiqeee ...</td>\n",
       "      <td>@coopefnbr @Jeffiwnl @nowaylildavid @Matiqeee ...</td>\n",
       "      <td>[@coopefnbr, @jeffiwnl, @nowaylildavid, @matiq...</td>\n",
       "      <td>@coopefnbr @jeffiwnl @nowaylildavid @matiqeee ...</td>\n",
       "      <td>[@coopefnbr, @jeffiwnl, @nowaylildavid, @matiq...</td>\n",
       "      <td>@coopefnbr @jeffiwnl @nowaylildavid @matiqeee ...</td>\n",
       "      <td>[coopefnbr, jeffiwnl, nowaylildavid, matiqeee,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12986</th>\n",
       "      <td>12986</td>\n",
       "      <td>12986</td>\n",
       "      <td>You’re proving my point that emotional fans li...</td>\n",
       "      <td>NormandeForeman</td>\n",
       "      <td>2</td>\n",
       "      <td>953</td>\n",
       "      <td>you, ’, re, proving, my, point, that, emotiona...</td>\n",
       "      <td>you’re proving my point that emotional fans li...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>You’re proving my point that emotional fans li...</td>\n",
       "      <td>You’re proving my point that emotional fans li...</td>\n",
       "      <td>[you’re, proving, point, emotional, fans, can’...</td>\n",
       "      <td>you’re proving point emotional fans can’t dist...</td>\n",
       "      <td>[prove, point, emotional, fan, distinction, pl...</td>\n",
       "      <td>prove point emotional fan distinction play car...</td>\n",
       "      <td>[prove, point, emotional, fan, distinction, pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12987</th>\n",
       "      <td>12987</td>\n",
       "      <td>12987</td>\n",
       "      <td>The Head of Deutsche Bank needs to find their ...</td>\n",
       "      <td>SolidarityRnwd</td>\n",
       "      <td>1</td>\n",
       "      <td>1103</td>\n",
       "      <td>the, head, of, deutsche, bank, needs, to, find...</td>\n",
       "      <td>the head of deutsche bank needs to find their ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>The Head of Deutsche Bank needs to find their ...</td>\n",
       "      <td>The Head of Deutsche Bank needs to find their ...</td>\n",
       "      <td>[head, deutsche, bank, needs, find, moral, com...</td>\n",
       "      <td>head deutsche bank needs find moral compass; l...</td>\n",
       "      <td>[head, deutsche, bank, needs, find, moral, com...</td>\n",
       "      <td>head deutsche bank needs find moral compass lo...</td>\n",
       "      <td>[head, deutsche, bank, needs, find, moral, com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12988</th>\n",
       "      <td>12988</td>\n",
       "      <td>12988</td>\n",
       "      <td>@SaraBarqawi Okay well my bowls will be either...</td>\n",
       "      <td>graemefraser</td>\n",
       "      <td>0</td>\n",
       "      <td>1553</td>\n",
       "      <td>okay, well, my, bowls, will, be, either, very,...</td>\n",
       "      <td>okay well my bowls will be either very small ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>@SaraBarqawi Okay well my bowls will be either...</td>\n",
       "      <td>@SaraBarqawi Okay well my bowls will be either...</td>\n",
       "      <td>[@sarabarqawi, okay, bowls, small, thin.]</td>\n",
       "      <td>@sarabarqawi okay bowls small thin.</td>\n",
       "      <td>[@sarabarqawi, okay, bowl, small, thin]</td>\n",
       "      <td>@sarabarqawi okay bowl small thin</td>\n",
       "      <td>[sarabarqawi, okay, bowl, small, thin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12989</th>\n",
       "      <td>12989</td>\n",
       "      <td>12989</td>\n",
       "      <td>@GrannyGloom, hello! https://t.co/gpdkdZMqfT</td>\n",
       "      <td>goblede</td>\n",
       "      <td>0</td>\n",
       "      <td>694</td>\n",
       "      <td>hello</td>\n",
       "      <td>hello</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>@GrannyGloom, hello! https://t.co/gpdkdZMqfT</td>\n",
       "      <td>@GrannyGloom, hello!</td>\n",
       "      <td>[@grannygloom,, hello!]</td>\n",
       "      <td>@grannygloom, hello!</td>\n",
       "      <td>[@grannygloom, hello]</td>\n",
       "      <td>@grannygloom hello</td>\n",
       "      <td>[grannygloom, hello]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12990 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1  \\\n",
       "0               0             0   \n",
       "1               1             1   \n",
       "2               2             2   \n",
       "3               3             3   \n",
       "4               4             4   \n",
       "...           ...           ...   \n",
       "12985       12985         12985   \n",
       "12986       12986         12986   \n",
       "12987       12987         12987   \n",
       "12988       12988         12988   \n",
       "12989       12989         12989   \n",
       "\n",
       "                                                   Tweet         Username  \\\n",
       "0      @FPL_Banger @Move78_FPL Yeah have for some tim...       fplbooster   \n",
       "1      @Simonhartmp - we haven’t moved on and just be...  bernardshawlive   \n",
       "2              @may_achie It's not our country anymore 😔       ChattyMan9   \n",
       "3      COL'S CRIMINAL LIBRARY: 2 BY MARK SAFRANKO htt...          col2910   \n",
       "4      6 months free, next goal is a year https://t.c...         TomLea__   \n",
       "...                                                  ...              ...   \n",
       "12985  @coopefnbr @Jeffiwnl @nowaylildavid @Matiqeee ...       TeekewFNBR   \n",
       "12986  You’re proving my point that emotional fans li...  NormandeForeman   \n",
       "12987  The Head of Deutsche Bank needs to find their ...   SolidarityRnwd   \n",
       "12988  @SaraBarqawi Okay well my bowls will be either...     graemefraser   \n",
       "12989       @GrannyGloom, hello! https://t.co/gpdkdZMqfT          goblede   \n",
       "\n",
       "       Retweets  Followers                                         CleanTweet  \\\n",
       "0             0       3314  yeah, have, for, some, time, now, yet, keep, s...   \n",
       "1             0       2287  -, we, haven, ’, t, moved, on, and, just, beca...   \n",
       "2             0       1269                it's, not, our, country, anymore, 😔   \n",
       "3             0       2234    col's, criminal, library, :, by, mark, safranko   \n",
       "4             0        208              months, free, next, goal, is, a, year   \n",
       "...         ...        ...                                                ...   \n",
       "12985         0       1351                                     init, bit, odd   \n",
       "12986         2        953  you, ’, re, proving, my, point, that, emotiona...   \n",
       "12987         1       1103  the, head, of, deutsche, bank, needs, to, find...   \n",
       "12988         0       1553  okay, well, my, bowls, will, be, either, very,...   \n",
       "12989         0        694                                              hello   \n",
       "\n",
       "                                             CleanTweet2 Vader_sent  \\\n",
       "0        yeah have for some time now yet keep scouting 😂   Positive   \n",
       "1       - we haven’t moved on and just because you sa...   Negative   \n",
       "2                         it's not our country anymore 😔   Positive   \n",
       "3             col's criminal library:  by mark safranko    Negative   \n",
       "4                       months free next goal is a year    Positive   \n",
       "...                                                  ...        ...   \n",
       "12985                                       init bit odd   Negative   \n",
       "12986  you’re proving my point that emotional fans li...   Positive   \n",
       "12987  the head of deutsche bank needs to find their ...   Negative   \n",
       "12988   okay well my bowls will be either very small ...   Positive   \n",
       "12989                                             hello     Neutral   \n",
       "\n",
       "      TextBlob_sent  Different_sent  Topic  \\\n",
       "0           Neutral               1     15   \n",
       "1          Negative               0     12   \n",
       "2           Neutral               1      2   \n",
       "3          Negative               0      7   \n",
       "4          Positive               0      1   \n",
       "...             ...             ...    ...   \n",
       "12985      Negative               0      8   \n",
       "12986       Neutral               1     12   \n",
       "12987      Positive               1      3   \n",
       "12988      Negative               1     15   \n",
       "12989       Neutral               0      4   \n",
       "\n",
       "                                       emoji_free_tweets  \\\n",
       "0      @FPL_Banger @Move78_FPL Yeah have for some tim...   \n",
       "1      @Simonhartmp - we haven’t moved on and just be...   \n",
       "2              @may_achie It's not our country anymore 😔   \n",
       "3      COL'S CRIMINAL LIBRARY: 2 BY MARK SAFRANKO htt...   \n",
       "4      6 months free, next goal is a year https://t.c...   \n",
       "...                                                  ...   \n",
       "12985  @coopefnbr @Jeffiwnl @nowaylildavid @Matiqeee ...   \n",
       "12986  You’re proving my point that emotional fans li...   \n",
       "12987  The Head of Deutsche Bank needs to find their ...   \n",
       "12988  @SaraBarqawi Okay well my bowls will be either...   \n",
       "12989       @GrannyGloom, hello! https://t.co/gpdkdZMqfT   \n",
       "\n",
       "                                         url_free_tweets  \\\n",
       "0      @FPL_Banger @Move78_FPL Yeah have for some tim...   \n",
       "1      @Simonhartmp - we haven’t moved on and just be...   \n",
       "2              @may_achie It's not our country anymore 😔   \n",
       "3            COL'S CRIMINAL LIBRARY: 2 BY MARK SAFRANKO    \n",
       "4                    6 months free, next goal is a year    \n",
       "...                                                  ...   \n",
       "12985  @coopefnbr @Jeffiwnl @nowaylildavid @Matiqeee ...   \n",
       "12986  You’re proving my point that emotional fans li...   \n",
       "12987  The Head of Deutsche Bank needs to find their ...   \n",
       "12988  @SaraBarqawi Okay well my bowls will be either...   \n",
       "12989                              @GrannyGloom, hello!    \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [@fpl_banger, @move78_fpl, yeah, time, now,, s...   \n",
       "1      [@simonhartmp, haven’t, moved, it,, doesn’t, s...   \n",
       "2                      [@may_achie, country, anymore, 😔]   \n",
       "3         [col's, criminal, library:, 2, mark, safranko]   \n",
       "4                         [6, months, free,, goal, year]   \n",
       "...                                                  ...   \n",
       "12985  [@coopefnbr, @jeffiwnl, @nowaylildavid, @matiq...   \n",
       "12986  [you’re, proving, point, emotional, fans, can’...   \n",
       "12987  [head, deutsche, bank, needs, find, moral, com...   \n",
       "12988          [@sarabarqawi, okay, bowls, small, thin.]   \n",
       "12989                            [@grannygloom,, hello!]   \n",
       "\n",
       "                                     tokens_back_to_text  \\\n",
       "0      @fpl_banger @move78_fpl yeah time now, scouting 😂   \n",
       "1      @simonhartmp haven’t moved it, doesn’t so. nee...   \n",
       "2                           @may_achie country anymore 😔   \n",
       "3                col's criminal library: 2 mark safranko   \n",
       "4                               6 months free, goal year   \n",
       "...                                                  ...   \n",
       "12985  @coopefnbr @jeffiwnl @nowaylildavid @matiqeee ...   \n",
       "12986  you’re proving point emotional fans can’t dist...   \n",
       "12987  head deutsche bank needs find moral compass; l...   \n",
       "12988                @sarabarqawi okay bowls small thin.   \n",
       "12989                               @grannygloom, hello!   \n",
       "\n",
       "                                                  lemmas  \\\n",
       "0       [@fpl_banger, @move78_fpl, yeah, time, scout, 😂]   \n",
       "1      [@simonhartmp, move, need, clear, lot, corrupt...   \n",
       "2                      [@may_achie, country, anymore, 😔]   \n",
       "3            [col, criminal, library, 2, mark, safranko]   \n",
       "4                           [6, month, free, goal, year]   \n",
       "...                                                  ...   \n",
       "12985  [@coopefnbr, @jeffiwnl, @nowaylildavid, @matiq...   \n",
       "12986  [prove, point, emotional, fan, distinction, pl...   \n",
       "12987  [head, deutsche, bank, needs, find, moral, com...   \n",
       "12988            [@sarabarqawi, okay, bowl, small, thin]   \n",
       "12989                              [@grannygloom, hello]   \n",
       "\n",
       "                                     lemmas_back_to_text  \\\n",
       "0              @fpl_banger @move78_fpl yeah time scout 😂   \n",
       "1      @simonhartmp move need clear lot corrupt liar ...   \n",
       "2                           @may_achie country anymore 😔   \n",
       "3                   col criminal library 2 mark safranko   \n",
       "4                                 6 month free goal year   \n",
       "...                                                  ...   \n",
       "12985  @coopefnbr @jeffiwnl @nowaylildavid @matiqeee ...   \n",
       "12986  prove point emotional fan distinction play car...   \n",
       "12987  head deutsche bank needs find moral compass lo...   \n",
       "12988                  @sarabarqawi okay bowl small thin   \n",
       "12989                                 @grannygloom hello   \n",
       "\n",
       "                                            lemma_tokens  \n",
       "0         [fpl_banger, move78_fpl, yeah, time, scout, 😂]  \n",
       "1      [simonhartmp, move, need, clear, lot, corrupt,...  \n",
       "2                       [may_achie, country, anymore, 😔]  \n",
       "3            [col, criminal, library, 2, mark, safranko]  \n",
       "4                           [6, month, free, goal, year]  \n",
       "...                                                  ...  \n",
       "12985  [coopefnbr, jeffiwnl, nowaylildavid, matiqeee,...  \n",
       "12986  [prove, point, emotional, fan, distinction, pl...  \n",
       "12987  [head, deutsche, bank, needs, find, moral, com...  \n",
       "12988             [sarabarqawi, okay, bowl, small, thin]  \n",
       "12989                               [grannygloom, hello]  \n",
       "\n",
       "[12990 rows x 19 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeb5526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "data_vectorized = vectorizer.fit_transform(df['lemmas_back_to_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9db50b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(error_score='raise',\n",
       "             estimator=LatentDirichletAllocation(learning_method=None,\n",
       "                                                 n_jobs=1),\n",
       "             n_jobs=1,\n",
       "             param_grid={'learning_decay': [0.5, 0.7, 0.9],\n",
       "                         'n_topics': [10, 15, 20, 30]},\n",
       "             return_train_score='warn')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Search Param\n",
    "search_params = {'n_components': [10, 15, 20, 25, 30], 'learning_decay': [.5, .7, .9]}\n",
    "\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "model.fit(data_vectorized)\n",
    "GridSearchCV(cv=None, error_score='raise',\n",
    "             estimator=LatentDirichletAllocation(batch_size=128, \n",
    "                                                 doc_topic_prior=None,\n",
    "                                                 evaluate_every=-1, \n",
    "                                                 learning_decay=0.7, \n",
    "                                                 learning_method=None,\n",
    "                                                 learning_offset=10.0, \n",
    "                                                 max_doc_update_iter=100, \n",
    "                                                 max_iter=10,\n",
    "                                                 mean_change_tol=0.001, \n",
    "                                                 n_components=10, \n",
    "                                                 n_jobs=1,\n",
    "                                                 perp_tol=0.1, \n",
    "                                                 random_state=None,\n",
    "                                                 topic_word_prior=None, \n",
    "                                                 total_samples=1000000.0, \n",
    "                                                 verbose=0),\n",
    "             n_jobs=1,\n",
    "             param_grid={'n_topics': [10, 15, 20, 30], \n",
    "                         'learning_decay': [0.5, 0.7, 0.9]},\n",
    "             pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
    "             scoring=None, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99e47dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.9, 'n_components': 10}\n",
      "Best Log Likelihood Score:  -389145.64494460623\n",
      "Model Perplexity:  15527.40783672409\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4309fda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to loop over number of topics to be used to find an \n",
    "#optimal number of tipics\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the \n",
    "    LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values_topic = []\n",
    "    model_list_topic = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaMulticore(corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list_topic.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values_topic.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list_topic, coherence_values_topic    \n",
    "# Can take a long time to run.\n",
    "model_list_topic, coherence_values_topic = compute_coherence_values(dictionary=id2word,\n",
    "                                                        corpus=corpus,\n",
    "                                                        texts=df['lemma_tokens'],\n",
    "                                                        start=2, limit=200, step=6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ea48fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph\n",
    "import matplotlib.pyplot as plt\n",
    "limit=200; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values_topic)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8b5d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5_2 = LdaMulticore(corpus=corpus,\n",
    "                       id2word=id2word,\n",
    "                       num_topics=150,\n",
    "                       random_state=42,\n",
    "                       chunksize=2000,\n",
    "                       passes=25,\n",
    "                       decay=0.9,\n",
    "                       iterations=70) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f079df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Topic 0 ------\n",
      "cool jeremyvineon5 crazy previous april petrol year source criticism tablet\n",
      "\n",
      "------ Topic 1 ------\n",
      "game play player boy lbc saturday reply girl jacob_rees_mogg cat\n",
      "\n",
      "------ Topic 2 ------\n",
      "kid exclusive potential people think trade delay support properly service\n",
      "\n",
      "------ Topic 3 ------\n",
      "debedee21 one battle 🤣 good site iandunt tech people sister\n",
      "\n",
      "------ Topic 4 ------\n",
      "😍 😘 thank 2 rise price son wonderful send year\n",
      "\n",
      "------ Topic 5 ------\n",
      "yes watch lol second google honestly work court finish suppose\n",
      "\n",
      "------ Topic 6 ------\n",
      "card fashion fast worker payment complete 💥 support look job\n",
      "\n",
      "------ Topic 7 ------\n",
      "list hard 😆 bear sure coffee work talk chocolate response\n",
      "\n",
      "------ Topic 8 ------\n",
      "👍 bloody drink sweet work today kwool kittytm3 tome_c vividutd\n",
      "\n",
      "------ Topic 9 ------\n",
      "star lmao super need people new mirror definition active putin\n",
      "\n",
      "------ Topic 10 ------\n",
      "🥳 dream april owner eu dave course look progress vacancy\n",
      "\n",
      "------ Topic 11 ------\n",
      "s easy scene pm go 90 l business musical journey\n",
      "\n",
      "------ Topic 12 ------\n",
      "idea away rest 😬 suffer marketing think thing good bag\n",
      "\n",
      "------ Topic 13 ------\n",
      "👏 word 🏾 favourite good ️ 👊 ha pick far\n",
      "\n",
      "------ Topic 14 ------\n",
      "stock na seo target credit d membership crisis pls find\n",
      "\n",
      "------ Topic 15 ------\n",
      "training nato room people coventry help look take free booking\n",
      "\n",
      "------ Topic 16 ------\n",
      "liverpool fun league blue lfc ben writing let milk join\n",
      "\n",
      "------ Topic 17 ------\n",
      "✅ far late good project right service suggest approve work\n",
      "\n",
      "------ Topic 18 ------\n",
      "mind 😀 thanks cancer right look thinking camp support find\n",
      "\n",
      "------ Topic 19 ------\n",
      "🤩 rate alra magazine day 🤝 average thank sussex xbox\n",
      "\n",
      "------ Topic 20 ------\n",
      "stuff fair video lady come till week grant winner tony\n",
      "\n",
      "------ Topic 21 ------\n",
      "🤣 beautiful wait 🙂 holiday game vaccine 3 crack mint\n",
      "\n",
      "------ Topic 22 ------\n",
      "🥺 arsenal train notice food dress interest charity fake trust\n",
      "\n",
      "------ Topic 23 ------\n",
      "😁 law electric shout know seed perfect ya good mile\n",
      "\n",
      "------ Topic 24 ------\n",
      "youtube mention channel expert got self 🙈 to gm today\n",
      "\n",
      "------ Topic 25 ------\n",
      "🎉 die m make hand good buddy villa day great\n",
      "\n",
      "------ Topic 26 ------\n",
      "yep expect order damn internet jacob present budget kitchen software\n",
      "\n",
      "------ Topic 27 ------\n",
      "head god manage challenge song require blow lunch school info\n",
      "\n",
      "------ Topic 28 ------\n",
      "park 💀 delivery april book day k marry read china\n",
      "\n",
      "------ Topic 29 ------\n",
      "2022 😎 £ 4 party gt change driver spring april\n",
      "\n",
      "------ Topic 30 ------\n",
      "let absolutely know xxx help find child information able people\n",
      "\n",
      "------ Topic 31 ------\n",
      "pass awful go cheese sit burn childhood ruin good man\n",
      "\n",
      "------ Topic 32 ------\n",
      "ball miss pen video bristol new church pot forgive jesus\n",
      "\n",
      "------ Topic 33 ------\n",
      "⬛ 🟩 human wordle 289 🟩🟩🟩🟩🟩 🟩🟩🟩 🟨 exciting 5/6\n",
      "\n",
      "------ Topic 34 ------\n",
      "wear mask boris johnson hi allow personal search government official\n",
      "\n",
      "------ Topic 35 ------\n",
      "😭 kind ready surprise egg recall concern meal available health\n",
      "\n",
      "------ Topic 36 ------\n",
      "time good wild year murder people £ spend ed royal\n",
      "\n",
      "------ Topic 37 ------\n",
      "fight pal middle donate negotiate work pm resign year need\n",
      "\n",
      "------ Topic 38 ------\n",
      "dm brilliant send website enter customer contact visit reading sorry\n",
      "\n",
      "------ Topic 39 ------\n",
      "going to stick good straight team think put green week\n",
      "\n",
      "------ Topic 40 ------\n",
      "p lord woman people programme 9 wide unbelievable come wait\n",
      "\n",
      "------ Topic 41 ------\n",
      "football walk body tip ️ 5 ⚽ complain review discover\n",
      "\n",
      "------ Topic 42 ------\n",
      "cut morning large time rock protect think resource scheme f\n",
      "\n",
      "------ Topic 43 ------\n",
      "️ ❤ 🤷 ♂ 🏻‍ instead thank day honest retweet\n",
      "\n",
      "------ Topic 44 ------\n",
      "night bed way appointment 🏿 familiar strange go delight be\n",
      "\n",
      "------ Topic 45 ------\n",
      "good 😊 luck ok comment thank hope glass stone time\n",
      "\n",
      "------ Topic 46 ------\n",
      "hey need relationship plant year look download khan learn freelance\n",
      "\n",
      "------ Topic 47 ------\n",
      "fucking 😡 jack like year call entirely superb review hand\n",
      "\n",
      "------ Topic 48 ------\n",
      "news appreciate thank symptom good ukrainian ward great new pitch\n",
      "\n",
      "------ Topic 49 ------\n",
      "thought ‍ ♂ 🤦 vibe ️ waste will work daughter\n",
      "\n",
      "------ Topic 50 ------\n",
      "👀 block lucky crypto people afraid ❄ private alert metaverse\n",
      "\n",
      "------ Topic 51 ------\n",
      "stop cold bad test real healthy case people etc medium\n",
      "\n",
      "------ Topic 52 ------\n",
      "probably taste beauty benefit brexit need financial 😜 evidence craft\n",
      "\n",
      "------ Topic 53 ------\n",
      "soon not area russians nope wind support nffc network onshore\n",
      "\n",
      "------ Topic 54 ------\n",
      "proper fully pep think squad vehicle 1 look total ian\n",
      "\n",
      "------ Topic 55 ------\n",
      "mph ° c rain mm wind | pressure legend temperature\n",
      "\n",
      "------ Topic 56 ------\n",
      "mate ai possible competition think paper disgusting say smell perfectly\n",
      "\n",
      "------ Topic 57 ------\n",
      "baby drive release ray library team respect time work mean\n",
      "\n",
      "------ Topic 58 ------\n",
      "love 💙 🤔 great money monday dad snap think 🎂\n",
      "\n",
      "------ Topic 59 ------\n",
      "😇 mood non great france journal morning 13 deny think\n",
      "\n",
      "------ Topic 60 ------\n",
      "💜 treat wrestlemania field tie time go thank jet bestie\n",
      "\n",
      "------ Topic 61 ------\n",
      "final cup lt;3 nhs world bowl time sun come fc\n",
      "\n",
      "------ Topic 62 ------\n",
      "twitter musk elon lose course goal free platform need speech\n",
      "\n",
      "------ Topic 63 ------\n",
      "yeah speak hello hang people limit get grow wait man\n",
      "\n",
      "------ Topic 64 ------\n",
      "congratulation newcastle board £ sam shut shortage deal come 24\n",
      "\n",
      "------ Topic 65 ------\n",
      "⬜ 🟩 🟨 🟩🟩🟩🟩🟩 289 wordle property 4/6 spur 🟩🟩🟩\n",
      "\n",
      "------ Topic 66 ------\n",
      "hate stupid box 🤪 blog wing today innovation preview slap\n",
      "\n",
      "------ Topic 67 ------\n",
      "bless gas rt mission people achieve help ️ understand genius\n",
      "\n",
      "------ Topic 68 ------\n",
      "🤗 home type weird gym dance talent 2012 extend chimenesuleyman\n",
      "\n",
      "------ Topic 69 ------\n",
      "🙏 sorry bro energy plan fantastic pop life conservative bank\n",
      "\n",
      "------ Topic 70 ------\n",
      "ask need police read remove open people new scary way\n",
      "\n",
      "------ Topic 71 ------\n",
      "ago year finally tweet funny couple incredible fear time day\n",
      "\n",
      "------ Topic 72 ------\n",
      "️ 04 piece ♥ 20 🏽 🙏 2022 dey britain\n",
      "\n",
      "------ Topic 73 ------\n",
      "✨ sex bbc aw single 💫 traffic know new mean\n",
      "\n",
      "------ Topic 74 ------\n",
      "red tonight 💖 worry boss nail call 🐾 🤞 😄\n",
      "\n",
      "------ Topic 75 ------\n",
      "shit account 😋 trussliz say people time £ tell tweet\n",
      "\n",
      "------ Topic 76 ------\n",
      "happy birthday ️ ☺ thank vote safe approach day advice\n",
      "\n",
      "------ Topic 77 ------\n",
      "happen certainly fine okay tbh bit worth point season suck\n",
      "\n",
      "------ Topic 78 ------\n",
      "cheer totally movie man van busy tough 🍻 new cake\n",
      "\n",
      "------ Topic 79 ------\n",
      "guess key 12 vs maths help describe great reach stage\n",
      "\n",
      "------ Topic 80 ------\n",
      "ur poster mouth trading attend leg strong say achievement boot\n",
      "\n",
      "------ Topic 81 ------\n",
      "return sale ramadan positive good pleasure ppl exchange issue muslims\n",
      "\n",
      "------ Topic 82 ------\n",
      "moment give book ticket sense clear clearly anniversary brain easily\n",
      "\n",
      "------ Topic 83 ------\n",
      "deserve sell garden begin gaming need time half warm meet\n",
      "\n",
      "------ Topic 84 ------\n",
      "amazing 🙌 day realise absolute hope thank want work great\n",
      "\n",
      "------ Topic 85 ------\n",
      "dog listen john repeat song station radio work 😳 know\n",
      "\n",
      "------ Topic 86 ------\n",
      "face value buy ticket apr fee plus protection loss 2\n",
      "\n",
      "------ Topic 87 ------\n",
      "afternoon good hot laugh page episode tea currently easter hopefully\n",
      "\n",
      "------ Topic 88 ------\n",
      "maybe enjoy pic 🦊 write 😢 new exercise month poetry\n",
      "\n",
      "------ Topic 89 ------\n",
      "run white class £ borisjohnson gt;&gt;&gt tory work decent 50\n",
      "\n",
      "------ Topic 90 ------\n",
      "check trip chance team range come building net 🥊 trailer\n",
      "\n",
      "------ Topic 91 ------\n",
      "set london 😃 think cancel 🌟 button look edit great\n",
      "\n",
      "------ Topic 92 ------\n",
      "series event catch king ticket book ️ come april look\n",
      "\n",
      "------ Topic 93 ------\n",
      "wish yesterday glad elonmusk share good resident x time thank\n",
      "\n",
      "------ Topic 94 ------\n",
      "choose mother open birth brand 😴 people great think step\n",
      "\n",
      "------ Topic 95 ------\n",
      "look forward line child blame airport country flight salah people\n",
      "\n",
      "------ Topic 96 ------\n",
      "rediscova vintage art mondaymotivation etsy ceramic interior homedecor interiordesign giftidea\n",
      "\n",
      "------ Topic 97 ------\n",
      "wonder poor big people instagram feel memory jamie need woman\n",
      "\n",
      "------ Topic 98 ------\n",
      "fan post film excellent bet deep min photo analysis apple\n",
      "\n",
      "------ Topic 99 ------\n",
      "u bite parent label relate free bank great entertainment new\n",
      "\n",
      "------ Topic 100 ------\n",
      "spot level water stand well quick april people think lot\n",
      "\n",
      "------ Topic 101 ------\n",
      "world eye awesome woman shame proud heart birmingham double look\n",
      "\n",
      "------ Topic 102 ------\n",
      "move 😹 build fancy mr assistant improve digital 💗 parsleysmum\n",
      "\n",
      "------ Topic 103 ------\n",
      "lie wow wrong city truth anymore session depend believe tv\n",
      "\n",
      "------ Topic 104 ------\n",
      "⠀ 👌 🚀 🤯 sadly good recovery apparently produce lisa\n",
      "\n",
      "------ Topic 105 ------\n",
      "😔 forest soul keen good bar day buy way fall\n",
      "\n",
      "------ Topic 106 ------\n",
      "😂 mum time know afford refer dude think take go\n",
      "\n",
      "------ Topic 107 ------\n",
      "car fall roll wife member fly fourfourtwo base rid £\n",
      "\n",
      "------ Topic 108 ------\n",
      "remotework write dark note shift therapy year work £ go\n",
      "\n",
      "------ Topic 109 ------\n",
      "come ⁠ well chelsea machine people weekend know place market\n",
      "\n",
      "------ Topic 110 ------\n",
      "🔥 remember group click link leave 💪 sign april let\n",
      "\n",
      "------ Topic 111 ------\n",
      "wake drop town manchester hit view time early 4 16\n",
      "\n",
      "------ Topic 112 ------\n",
      "x imagine iot thank leader pack day buy 9.2 person\n",
      "\n",
      "------ Topic 113 ------\n",
      "essexpr hall scerion fox protest survive beach designer multi time\n",
      "\n",
      "------ Topic 114 ------\n",
      "joke fit study weight save name march time condition future\n",
      "\n",
      "------ Topic 115 ------\n",
      "opinion interesting go prefer sick faith people hilarious india mess\n",
      "\n",
      "------ Topic 116 ------\n",
      "lovely ♀ definitely friend ‍ ️ 🙃 🤦 tho minister\n",
      "\n",
      "------ Topic 117 ------\n",
      "south topic b time 2 ️ take africa 1st 🏾‍\n",
      "\n",
      "------ Topic 118 ------\n",
      "v kim taehyung break grammys summer record drama love stan\n",
      "\n",
      "------ Topic 119 ------\n",
      "welcome interview james mad g shop shirt playlist steve cross\n",
      "\n",
      "------ Topic 120 ------\n",
      "road feel mogg rees gold say give people wrong johnson\n",
      "\n",
      "------ Topic 121 ------\n",
      "sleep gorgeous colour prove stream seriously thank fabulous look 🖤\n",
      "\n",
      "------ Topic 122 ------\n",
      "remind stake excited leeds weather 0 ooh queen liar bird\n",
      "\n",
      "------ Topic 123 ------\n",
      "decide ⬇ good time keep know trudiebakescake score wood ehrc\n",
      "\n",
      "------ Topic 124 ------\n",
      "russian ukraine war kill crime civilian russia £ force week\n",
      "\n",
      "------ Topic 125 ------\n",
      "job exactly question add stay death direct business nonsense way\n",
      "\n",
      "------ Topic 126 ------\n",
      "apply story fintech fund ft wwe role £ read year\n",
      "\n",
      "------ Topic 127 ------\n",
      "hope cry truly radio claim general idiot turn make sharrond62\n",
      "\n",
      "------ Topic 128 ------\n",
      "ehrc find year woman flat justice space sight time people\n",
      "\n",
      "------ Topic 129 ------\n",
      "ukraine hire help people assume focus cam young vote uk\n",
      "\n",
      "------ Topic 130 ------\n",
      "grammy past completely success win fix light spread ramadan twice\n",
      "\n",
      "------ Topic 131 ------\n",
      "fail europe surely daily pandemic fuel give nazi assessment kick\n",
      "\n",
      "------ Topic 132 ------\n",
      "oh old thread dear day hear year god thank 7\n",
      "\n",
      "------ Topic 133 ------\n",
      "long term lead issue correct hold option time possibly apologise\n",
      "\n",
      "------ Topic 134 ------\n",
      "guy award space floor 4th know day ig look business\n",
      "\n",
      "------ Topic 135 ------\n",
      "ah literally new taurus time working refund good beer thank\n",
      "\n",
      "------ Topic 136 ------\n",
      "tell company nah travel cos character way drug dr side\n",
      "\n",
      "------ Topic 137 ------\n",
      "black location horrendous sky ukraine kane 😌 n surprised tesco\n",
      "\n",
      "------ Topic 138 ------\n",
      "😉 😩 tune 💛 door nft 🧡 good inspire late\n",
      "\n",
      "------ Topic 139 ------\n",
      "photo 👇 🏼 picture c omg ° bother earth everton\n",
      "\n",
      "------ Topic 140 ------\n",
      "thank nice haha 😅 update image 👋 family gift need\n",
      "\n",
      "------ Topic 141 ------\n",
      "confirm message work arrive johnsonout70 secure £ chair go day\n",
      "\n",
      "------ Topic 142 ------\n",
      "match cute demand public need choice say thankyou respond work\n",
      "\n",
      "------ Topic 143 ------\n",
      "sound pretty xx 🙄 💕 answer performance eat try phone\n",
      "\n",
      "------ Topic 144 ------\n",
      "people sort wanna avoid compare think good thing contract need\n",
      "\n",
      "------ Topic 145 ------\n",
      "🏻 manager need chris come day zone toy pakistan good\n",
      "\n",
      "------ Topic 146 ------\n",
      "little music recommend work gmb tour cheap weekend highly new\n",
      "\n",
      "------ Topic 147 ------\n",
      "🥰 agree dead doubt fact criminal copy hair problem look\n",
      "\n",
      "------ Topic 148 ------\n",
      "true forget congrats yellow paint season store ride border go\n",
      "\n",
      "------ Topic 149 ------\n",
      "fuck 6 chat normal come look coach go thank madness\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in model_5_2.print_topics(num_topics=150, num_words=20)]\n",
    "# Create Topics\n",
    "topics = [' '.join(t[0:10]) for t in words]\n",
    "# Getting the topics\n",
    "for id, t in enumerate(topics): \n",
    "    print(f\"------ Topic {id} ------\")\n",
    "    print(t, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "57a99bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(25, 0.20063767), (42, 0.20067926), (44, 0.100637175), (103, 0.1006757), (111, 0.3006804)]\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "topic_values = model_5_2[corpus]\n",
    "print(topic_values[6049])\n",
    "print(max(topic_values[6049], key = lambda i : i[1])[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
